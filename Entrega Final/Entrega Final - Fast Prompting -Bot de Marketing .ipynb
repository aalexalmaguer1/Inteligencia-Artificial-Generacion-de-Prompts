{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51de8434",
   "metadata": {},
   "source": [
    "# *Entrega Final Fast Prompting en Acción*\n",
    "## *Bot de Marketing*\n",
    "#### *Nombre: José Alejandro Almaguer Tamez*\n",
    "#### *Curso: Inteligencia artificial: Generación de Prompts*\n",
    "#### *Comisión #61255*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b64f849",
   "metadata": {},
   "source": [
    "## Función Calling\n",
    "#### El término \"función calling\" no es un término estándar en el campo de la inteligencia artificial o la programación en general. Si te refieres al acto de \"llamar a una función\" (function calling en inglés), esto describe el proceso en programación donde se ejecuta una función o método definido en el código. Al llamar a una función, puedes pasarle argumentos o datos para que la función los procese y, a menudo, devuelva un resultado. Este concepto es fundamental en la programación y se utiliza en prácticamente todos los lenguajes de programación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f1a24",
   "metadata": {},
   "source": [
    "## Consigna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1b059",
   "metadata": {},
   "source": [
    "### Nombre del proyecto: Marketing Accesible para PYMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a6137",
   "metadata": {},
   "source": [
    "### Problema a abordar\n",
    "#### El proyecto se centra en el desafío que enfrentan las pequeñas y medianas empresas (PyMEs) para producir contenido de marketing digital atractivo y efectivo con recursos limitados. Estas empresas a menudo carecen del personal, tiempo y experiencia necesarios para generar consistentemente contenido de alta calidad, como textos publicitarios, imágenes atractivas y manejo de redes sociales. Esta carencia puede llevar a una menor visibilidad en línea, lo que es vital para atraer y mantener clientes en la era digital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c325d91",
   "metadata": {},
   "source": [
    "### Desarrollo de la propuesta de solución\n",
    "#### Generación de Texto: Los prompts podrían incluir información sobre el producto/servicio, el tono deseado (profesional, informal, persuasivo), y palabras clave específicas. Ejemplo: \"Crea una publicación de blog informativa sobre calzado deportivo ecológico en un tono amigable y accesible.\"\n",
    "\n",
    "#### Generación de Imágenes: Se utilizarán descripciones detalladas del tipo de imagen necesaria, incluyendo el estilo, colores de la marca, y elementos a incluir. Ejemplo: \"Genera una imagen para un anuncio de calzado deportivo ecológico que muestre el producto en un entorno urbano, con una paleta de colores verde y azul.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beedbb2",
   "metadata": {},
   "source": [
    "### Justificación de la viabilidad del proyecto\n",
    "#### En el modelo Chat GPT 3.5 Turbo, la generación de texto de un prompt de 100 caracteres tiene un costo de 26.5 tokens. Si damos una respuesta de 150 tokens daría un total de 176.5 tokens\n",
    "#### La formula para calcular el costo sería \"Costo en dolares = (Total de tokens/1000) * Tarifa por 1000 tokens\"\n",
    "#### Es importante mencionar que el costo del modelo Chat GPT-3 Turbo es de \n",
    "#### 0.0010 USD por 1K tokens de Input y 0.0020 USD por 1K tokens de Output\n",
    "#### Mientras que el costo de generar una imagen en Dalle 3 de 1024 x 1024 es de 0.040 USD por imagen \n",
    "#### Debido a esto el costo aproximado por ejecutar los prompts es el siguiente: (Lo calcule para el prompt que utilizare)\n",
    "### *El costo se añadío al Final del Proyecto*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620fd49",
   "metadata": {},
   "source": [
    "#### La solucion basada en I.A aborda el problema de recursos limitados en las PyMEs, ofreciendo una alternativa económica y eficiente a la contratación de equipos de marketing especializados. Además, la flexibilidad y capacidad de personalización de los modelos de IA aseguran que el contenido generado sea relevante y de alta calidad, adaptándose a las necesidades específicas de cada empresa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e623e",
   "metadata": {},
   "source": [
    "### Objetivos\n",
    "#### Facilitar el alcance de las PYMES en sus comercios electronicos o fisicos\n",
    "#### Automatizar la generación de contenido de alta calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a1887c",
   "metadata": {},
   "source": [
    "### Metodología \n",
    "#### Se integrara la API de OpenAI para la automatizacion de generación de texto y contenido gráfico. \n",
    "#### Se realizarán pruebas y ajustes continuos para garantizar la calidad y relevancia del contenido generado.\n",
    "#### Se generara texto y contenido grafico para las PYMES a bajo costo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206da318",
   "metadata": {},
   "source": [
    "### Herramientas de prompting\n",
    "#### Las herramientas de prompting que se utilizaran son el modelo Chat GPT 3.5 Turbo para la generación de texto y Dalle 3 para la generación de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c90a0",
   "metadata": {},
   "source": [
    "### Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69de47",
   "metadata": {},
   "source": [
    "###### *0.Actualizar Chat Gpt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1359430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\users\\profe\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\profe\\anaconda3\\lib\\site-packages (from openai==0.28) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\profe\\anaconda3\\lib\\site-packages (from openai==0.28) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\profe\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\profe\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb0e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148bcf6",
   "metadata": {},
   "source": [
    "#### *1. Import openAI dependences (load with conda install openai)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee3d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import openAI dependences (module)\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c35c42",
   "metadata": {},
   "source": [
    "#### *2. Use the API Key from openAI page*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67eaa4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add our API Key copied from openAI page\n",
    "openai.api_key = \"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\" #Example -> dw-bQyr9128F49VJRNKAnST32l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ca24d",
   "metadata": {},
   "source": [
    "#### *3. Make a función calling (def)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a008b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_product(recomendation_quantity):\n",
    "    # Welcome print\n",
    "    print(\"Bienvenido, te realizaremos unas preguntas para ayudarte a crear la descripción de tu producto\")\n",
    "\n",
    "    # Ask for a product name\n",
    "    product = input(\"1. ¿Cual es el producto que promocionaras? \")\n",
    "\n",
    "    # Ask for a description of the product\n",
    "    description_pro = input(\"2. ¿Cual es la descripción del producto? \")\n",
    "\n",
    "    # Ask for a tone\n",
    "    tone = input(\"3. ¿Cual es el tono que buscar para la publicación(amigable,serio, etc.)? \")\n",
    "\n",
    "    # Formatea las respuestas en un prompt para la API de OpenAI\n",
    "    prompt = f\"Realiza una descripcion para promocionar el producto {product} en redes sociales.La descripción del producto es  {description_pro} y el tono de la publicación será {tone}.\"\n",
    "\n",
    "    conversation = [{\"role\": \"user\", \"content\": prompt}] # One request\n",
    "\n",
    "    # Make the request\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=conversation,\n",
    "        max_tokens=50\n",
    "    )\n",
    "\n",
    "    # Obtiene la descripcion\n",
    "    description = response.choices[0]['message']\n",
    "\n",
    "    # Make a request \n",
    "    recomendations = []\n",
    "    for _ in range(recomendation_quantity):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=50\n",
    "        )\n",
    "\n",
    "        # Get the review and add to the array\n",
    "        description = response.choices[0]['message']['content']\n",
    "        recomendations.append(description)\n",
    "\n",
    "    # Make a dictionary\n",
    "    result_json = {\n",
    "        \"product \": product ,\n",
    "        \"description_pro\": description_pro,\n",
    "        \"tone\": tone,\n",
    "        \"descripcion\": recomendations\n",
    "    }\n",
    "\n",
    "    # Return in JSON format\n",
    "    return json.dumps(result_json, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abdf741",
   "metadata": {},
   "source": [
    "#### *4. Settings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c891462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenido, te realizaremos unas preguntas para ayudarte a crear la descripción de tu producto\n",
      "1. ¿Cual es el producto que promocionaras? Arenero para gato\n",
      "2. ¿Cual es la descripción del producto? Arenero para gato que se limpia con solo presionar un botón\n",
      "3. ¿Cual es el tono que buscar para la publicación(amigable,serio, etc.)? Amigable\n",
      "{\n",
      "  \"product \": \"Arenero para gato\",\n",
      "  \"description_pro\": \"Arenero para gato que se limpia con solo presionar un bot\\u00f3n\",\n",
      "  \"tone\": \"Amigable\",\n",
      "  \"descripcion\": [\n",
      "    \"\\u00a1Adi\\u00f3s a la molestia de limpiar la caja de arena de tu gato! \\ud83d\\ude3b\\ud83d\\udeab Con nuestro Arenero para gato de f\\u00e1cil limpieza, tendr\\u00e1s m\\u00e1s tiempo para disfrutar de tu compa\\u00f1ero\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Make the request\n",
    "respuesta_json = get_description_product(1)\n",
    "print(respuesta_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "809affb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product ': 'Arenero para gato',\n",
       " 'description_pro': 'Arenero para gato que se limpia con solo presionar un botón',\n",
       " 'tone': 'Amigable',\n",
       " 'descripcion': ['¡Adiós a la molestia de limpiar la caja de arena de tu gato! 😻🚫 Con nuestro Arenero para gato de fácil limpieza, tendrás más tiempo para disfrutar de tu compañero']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the formated json\n",
    "display(json.loads(respuesta_json))\n",
    "\n",
    "# If you want to show the json in the web, you could enter to: https://jsonformatter.curiousconcept.com/#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6aafcb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copia y pega la descripción que te dio el prompt. ¡Adiós a la molestia de limpiar la caja de arena de tu gato! Con nuestro Arenero para gato de fácil limpieza, tendrás más tiempo para disfrutar de tu compañero'\n",
      "Añade otra vez el nombre del producto que se promocionara. Arenero para gato que se limpia con solo presionar un botón\n"
     ]
    }
   ],
   "source": [
    "description = input(\"Copia y pega la descripción que te dio el prompt. \")\n",
    "product = input(\"Añade otra vez el nombre del producto que se promocionara. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8e200b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use story_made as the context for a new prompt\n",
    "process_text_to_image = f\"Crea un prompt que sirva para generar una imagen de manera optima. El prompt debera estar basado en esta descripción {description}.Debe incluir el producto {product}.Solamente indica que debe de tener la imagen\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4057c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new user message with story_made as the context\n",
    "conversation = [{\"role\": \"user\", \"content\": process_text_to_image}] # One request\n",
    "conversation.append({\"role\": \"user\", \"content\": process_text_to_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b5b9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt de la escena: Genera una imagen optimizada del Arenero para gato de fácil limpieza con solo presionar un botón. La imagen debe reflejar la comodidad y conveniencia de este producto, permitiendo a los usuarios disfrutar más tiempo con su compañero felino sin la molestia de limpiar la caja de arena.\n"
     ]
    }
   ],
   "source": [
    "# Make the request for the new prompt\n",
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=conversation,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "# Get and print the new story\n",
    "img_prompt = response['choices'][0]['message']['content'].strip()\n",
    "print(\"Prompt de la escena:\", img_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89774820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-LxZi761P1AXwkfDdEb1ojo17/user-E1Nqo4YqofVlukfEX3YHmZ70/img-gxFLeS7oWqvp8lJlBdZl2fo0.png?st=2024-01-30T05%3A10%3A37Z&se=2024-01-30T07%3A10%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-01-30T00%3A34%3A47Z&ske=2024-01-31T00%3A34%3A47Z&sks=b&skv=2021-08-06&sig=ELhegmoZZTBusSZXAqS8hTYOxeS1P4Ul2TfQaYvSVto%3D\n"
     ]
    }
   ],
   "source": [
    "# Now use story_made as the context for a new prompt\n",
    "image_from_scenario = f\" En base a la historia anterior, crea una imagen que represente el escenario descrito : {img_prompt}\"\n",
    "\n",
    "# Add the new user message with the image prompt\n",
    "conversation.append({\"role\": \"user\", \"content\": image_from_scenario})\n",
    "\n",
    "# Make the request for the image prompt\n",
    "image_response = openai.Image.create(\n",
    "    prompt=image_from_scenario,\n",
    "    n=1,\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "# Get and print the generated image URL\n",
    "print(image_response['data'][0]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d4aec",
   "metadata": {},
   "source": [
    "## *Calculo del Costo del Prompt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "37564d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"{get_description_product}\"\n",
    "prompt_tokens = len(prompt) / 4\n",
    "response_tokens = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "451c8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarifas para Chat GPT 3.5 Turbo\n",
    "tarifa_input_por_1000_tokens = 0.0010\n",
    "tarifa_output_por_1000_tokens = 0.0020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c270e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del costo del primer prompt para Chat GPT 3.5 Turbo. El primer prompt es el anuncio que se publicara\n",
    "costo_input1 = (prompt_tokens / 1000) * tarifa_input_por_1000_tokens\n",
    "costo_output1 = (response_tokens / 1000) * tarifa_output_por_1000_tokens\n",
    "costo_total_chat_gpt1 = costo_input1 + costo_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5989fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del costo del segundo prompt para Chat GPT 3.5 Turbo. El segundo prompt adapta el primer prompt para la generacion de una imagen\n",
    "costo_input2 = (response_tokens / 1000) * tarifa_input_por_1000_tokens\n",
    "costo_output2 = (response_tokens / 1000) * tarifa_output_por_1000_tokens\n",
    "costo_total_chat_gpt2 = costo_input2 + costo_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "100ba39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del costo total de los prompts de Chat GPT 3.5 Turbo\n",
    "costo_total_chat_gpt = costo_total_chat_gpt1 + costo_total_chat_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d129621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costo adicional por usar DALL-E 3\n",
    "costo_dalle_por_imagen = 0.040  # Costo por imagen de 1024x1024 en dólares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a46964a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El costo total es: 0.040264 dólares\n"
     ]
    }
   ],
   "source": [
    "# Costo total incluyendo Chat GPT 3.5 Turbo y DALL-E 3\n",
    "costo_total = costo_total_chat_gpt + costo_dalle_por_imagen\n",
    "print(f\"El costo total es: {costo_total} dólares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c6229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
